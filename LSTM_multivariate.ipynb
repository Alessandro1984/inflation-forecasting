{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772ceb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 17:41:58.194058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(234)\n",
    "tf.random.set_seed(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f504a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ade2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = df_us.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4e95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us.columns = [x.lower() for x in df_us.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bad80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'dff', 'cpiaucsl', 'cpilfesl', 'unrate', 'wtisplc', 'indpro',\n",
       "       'mabmm301usm189s', 'a576rc1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efff113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>dff</th>\n",
       "      <th>cpiaucsl</th>\n",
       "      <th>cpilfesl</th>\n",
       "      <th>unrate</th>\n",
       "      <th>wtisplc</th>\n",
       "      <th>indpro</th>\n",
       "      <th>mabmm301usm189s</th>\n",
       "      <th>a576rc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.24095</td>\n",
       "      <td>2.00669</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.97</td>\n",
       "      <td>10.03675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.05509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1.41379</td>\n",
       "      <td>2.34114</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.97</td>\n",
       "      <td>6.96284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.78233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.51881</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.97</td>\n",
       "      <td>4.49722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.93518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.93237</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.97</td>\n",
       "      <td>1.50636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.56845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.82507</td>\n",
       "      <td>1.66113</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.97</td>\n",
       "      <td>-0.11438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.94632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2.56</td>\n",
       "      <td>8.21485</td>\n",
       "      <td>6.64296</td>\n",
       "      <td>3.5</td>\n",
       "      <td>84.26</td>\n",
       "      <td>4.73131</td>\n",
       "      <td>2.56370</td>\n",
       "      <td>9.07203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7.76249</td>\n",
       "      <td>6.30176</td>\n",
       "      <td>3.7</td>\n",
       "      <td>87.55</td>\n",
       "      <td>3.18912</td>\n",
       "      <td>1.28501</td>\n",
       "      <td>8.07029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>3.78</td>\n",
       "      <td>7.13535</td>\n",
       "      <td>5.97198</td>\n",
       "      <td>3.6</td>\n",
       "      <td>84.37</td>\n",
       "      <td>1.98468</td>\n",
       "      <td>0.02623</td>\n",
       "      <td>7.43424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.44494</td>\n",
       "      <td>5.70386</td>\n",
       "      <td>3.5</td>\n",
       "      <td>76.44</td>\n",
       "      <td>1.14673</td>\n",
       "      <td>-1.31457</td>\n",
       "      <td>6.94998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.34716</td>\n",
       "      <td>5.54757</td>\n",
       "      <td>3.4</td>\n",
       "      <td>78.12</td>\n",
       "      <td>0.78956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.86180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time   dff  cpiaucsl  cpilfesl  unrate  wtisplc    indpro  \\\n",
       "0    1960-01-01  3.99   1.24095   2.00669     5.2     2.97  10.03675   \n",
       "1    1960-02-01  3.97   1.41379   2.34114     4.8     2.97   6.96284   \n",
       "2    1960-03-01  3.84   1.51881   2.00000     5.4     2.97   4.49722   \n",
       "3    1960-04-01  3.92   1.93237   2.00000     5.2     2.97   1.50636   \n",
       "4    1960-05-01  3.85   1.82507   1.66113     5.1     2.97  -0.11438   \n",
       "..          ...   ...       ...       ...     ...      ...       ...   \n",
       "752  2022-09-01  2.56   8.21485   6.64296     3.5    84.26   4.73131   \n",
       "753  2022-10-01  3.08   7.76249   6.30176     3.7    87.55   3.18912   \n",
       "754  2022-11-01  3.78   7.13535   5.97198     3.6    84.37   1.98468   \n",
       "755  2022-12-01  4.10   6.44494   5.70386     3.5    76.44   1.14673   \n",
       "756  2023-01-01  4.33   6.34716   5.54757     3.4    78.12   0.78956   \n",
       "\n",
       "     mabmm301usm189s  a576rc1  \n",
       "0                NaN  7.05509  \n",
       "1                NaN  6.78233  \n",
       "2                NaN  5.93518  \n",
       "3                NaN  5.56845  \n",
       "4                NaN  4.94632  \n",
       "..               ...      ...  \n",
       "752          2.56370  9.07203  \n",
       "753          1.28501  8.07029  \n",
       "754          0.02623  7.43424  \n",
       "755         -1.31457  6.94998  \n",
       "756              NaN  7.86180  \n",
       "\n",
       "[757 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862814e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate first differences and drop NA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_us_diff \u001b[38;5;241m=\u001b[39m \u001b[43mdf_us\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Rename axis\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_us_diff \u001b[38;5;241m=\u001b[39m df_us_diff\u001b[38;5;241m.\u001b[39mrename_axis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindicator\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/frame.py:9227\u001b[0m, in \u001b[0;36mDataFrame.diff\u001b[0;34m(self, periods, axis)\u001b[0m\n\u001b[1;32m   9224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m periods \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   9225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshift(periods, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m-> 9227\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.diff\u001b[0;34m(self, n, axis)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiff\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, n: \u001b[38;5;28mint\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    418\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_axis(axis)\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1275\u001b[0m, in \u001b[0;36mBlock.diff\u001b[0;34m(self, n, axis)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiff\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return block for the diff of the values\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1275\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(values\u001b[38;5;241m=\u001b[39mnew_values)]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/algorithms.py:1779\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(arr, n, axis)\u001b[0m\n\u001b[1;32m   1776\u001b[0m     _lag_indexer[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m-\u001b[39mn) \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m-\u001b[39mn, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1777\u001b[0m     lag_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_lag_indexer)\n\u001b[0;32m-> 1779\u001b[0m     out_arr[res_indexer] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres_indexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlag_indexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_timedelta:\n\u001b[1;32m   1782\u001b[0m     out_arr \u001b[38;5;241m=\u001b[39m out_arr\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimedelta64[ns]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Calculate first differences and drop NA\n",
    "df_us_diff = df_us.diff().dropna()\n",
    "\n",
    "# Rename axis\n",
    "df_us_diff = df_us_diff.rename_axis('indicator', axis=1)\n",
    "\n",
    "# Create plot using Plotly\n",
    "import plotly.express as px\n",
    "fig = px.line(df_us_diff.iloc[:,0:8], facet_col=\"indicator\", facet_col_wrap=1) \n",
    "fig.update_yaxes(visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe46f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    print('Results of Augmented Dickey-Fuller Test:')\n",
    "    adf = adfuller(timeseries, autolag='AIC')\n",
    "    output = pd.Series(adf[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in adf[4].items():\n",
    "        output['Critical Value (%s)'%key] = value\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d22abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test:  time\n",
      "Results of Augmented Dickey-Fuller Test:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1960-01-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indi \u001b[38;5;129;01min\u001b[39;00m df_us:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADF Test: \u001b[39m\u001b[38;5;124m'\u001b[39m, indi)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43madf_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_us\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_us[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpiaucsl\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m df_us[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpiaucsl\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdiff()\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#df_us[['cpilfesl']] = df_us[['cpilfesl']].diff().dropna()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36madf_test\u001b[0;34m(timeseries)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madf_test\u001b[39m(timeseries):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults of Augmented Dickey-Fuller Test:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     adf \u001b[38;5;241m=\u001b[39m \u001b[43madfuller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautolag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAIC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(adf[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Statistic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp-value\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#Lags Used\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Observations Used\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key,value \u001b[38;5;129;01min\u001b[39;00m adf[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/statsmodels/tsa/stattools.py:260\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    166\u001b[0m     x,\n\u001b[1;32m    167\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    172\u001b[0m ):\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    See example notebook\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43marray_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    262\u001b[0m     regression \u001b[38;5;241m=\u001b[39m rename_trend(regression)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/statsmodels/tools/validation/validation.py:135\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional \u001b[38;5;129;01mand\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxdim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m maxdim:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/pandas/core/generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1960-01-01'"
     ]
    }
   ],
   "source": [
    "for indi in df_us:\n",
    "    print('ADF Test: ', indi)\n",
    "    adf_test(df_us[[indi]])\n",
    "\n",
    "df_us[['cpiaucsl']] = df_us[['cpiaucsl']].diff().dropna()\n",
    "#df_us[['cpilfesl']] = df_us[['cpilfesl']].diff().dropna()\n",
    "df_us[['unrate']] = df_us[['unrate']].diff().dropna()\n",
    "df_us[['wtisplc']] = df_us[['wtisplc']].diff().dropna()\n",
    "df_us[['indpro']] = df_us[['indpro']].diff().dropna()\n",
    "df_us[['mabmm301usm189s']] = df_us[['mabmm301usm189s']].diff().dropna()\n",
    "df_us[['a576rc1']] = df_us[['a576rc1']].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "\n",
    "for indi in df_us:\n",
    "    result = adfuller(df_us[indi])\n",
    "    print('ADF Test: ', indi)\n",
    "    if result[1] < 0.05:\n",
    "        print('Series is stationary')\n",
    "    else:\n",
    "        print('Series is not stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7161ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "maxlag = 12\n",
    "test = 'ssr_chi2test'\n",
    "target_var = 'cpilfesl'\n",
    "\n",
    "def grangers_causation_matrix(data, variables, target, test='ssr_chi2test', verbose=False):    \n",
    "   \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c, target]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1], 4) for i in range(maxlag)]\n",
    "            if verbose: \n",
    "                print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "# drop the 'indicator' column since it's not a relevant variable\n",
    "#df_us_diff = df_us_diff.drop('indicator', axis=1)\n",
    "\n",
    "# get the variables in the dataframe (excluding the target variable)\n",
    "variables = list(df_us_diff.columns)\n",
    "variables.remove(target_var)\n",
    "\n",
    "# run the Granger causality test\n",
    "grangers_causation_matrix(df_us_diff, variables=variables, target=target_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edff646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d54c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(757, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only stationary features are included\n",
    "\n",
    "feat_df = df_us.drop(['wtisplc', 'cpilfesl','time','mabmm301usm189s'], axis = 1)\n",
    "\n",
    "feat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e04d50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df['cpilfesl']=df_us['cpilfesl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2131b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dff</th>\n",
       "      <th>cpiaucsl</th>\n",
       "      <th>unrate</th>\n",
       "      <th>indpro</th>\n",
       "      <th>a576rc1</th>\n",
       "      <th>cpilfesl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.99</td>\n",
       "      <td>1.24095</td>\n",
       "      <td>5.2</td>\n",
       "      <td>10.03675</td>\n",
       "      <td>7.05509</td>\n",
       "      <td>2.00669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.97</td>\n",
       "      <td>1.41379</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.96284</td>\n",
       "      <td>6.78233</td>\n",
       "      <td>2.34114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.84</td>\n",
       "      <td>1.51881</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.49722</td>\n",
       "      <td>5.93518</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.92</td>\n",
       "      <td>1.93237</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.50636</td>\n",
       "      <td>5.56845</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.85</td>\n",
       "      <td>1.82507</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-0.11438</td>\n",
       "      <td>4.94632</td>\n",
       "      <td>1.66113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2.56</td>\n",
       "      <td>8.21485</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.73131</td>\n",
       "      <td>9.07203</td>\n",
       "      <td>6.64296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>3.08</td>\n",
       "      <td>7.76249</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.18912</td>\n",
       "      <td>8.07029</td>\n",
       "      <td>6.30176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>3.78</td>\n",
       "      <td>7.13535</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.98468</td>\n",
       "      <td>7.43424</td>\n",
       "      <td>5.97198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>4.10</td>\n",
       "      <td>6.44494</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.14673</td>\n",
       "      <td>6.94998</td>\n",
       "      <td>5.70386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>4.33</td>\n",
       "      <td>6.34716</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.78956</td>\n",
       "      <td>7.86180</td>\n",
       "      <td>5.54757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dff  cpiaucsl  unrate    indpro  a576rc1  cpilfesl\n",
       "0    3.99   1.24095     5.2  10.03675  7.05509   2.00669\n",
       "1    3.97   1.41379     4.8   6.96284  6.78233   2.34114\n",
       "2    3.84   1.51881     5.4   4.49722  5.93518   2.00000\n",
       "3    3.92   1.93237     5.2   1.50636  5.56845   2.00000\n",
       "4    3.85   1.82507     5.1  -0.11438  4.94632   1.66113\n",
       "..    ...       ...     ...       ...      ...       ...\n",
       "752  2.56   8.21485     3.5   4.73131  9.07203   6.64296\n",
       "753  3.08   7.76249     3.7   3.18912  8.07029   6.30176\n",
       "754  3.78   7.13535     3.6   1.98468  7.43424   5.97198\n",
       "755  4.10   6.44494     3.5   1.14673  6.94998   5.70386\n",
       "756  4.33   6.34716     3.4   0.78956  7.86180   5.54757\n",
       "\n",
       "[757 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a49689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train, test split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainX, testX, trainy, testy = train_test_split(feat_df.drop('cpilfesl', axis=1), feat_df['cpilfesl'], test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffadde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#fit and transform trainX\n",
    "trainX_scaled = scaler.fit_transform(trainX)\n",
    "\n",
    "# fit and transform testX\n",
    "testX_scaled = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b333884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()    \n",
    "    for i in range(len(sequences)):\n",
    "        #find end of pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "\n",
    "        \n",
    "        #check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        \n",
    "        #gather input and output\n",
    "        seq_x, seq_y = sequences.iloc[i:end_ix, :-1], sequences.iloc[end_ix - 1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b9d7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train adding cpilfesl\n",
    "trainX['cpilfesl'] = trainy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a1cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testX adding cpilfesl\n",
    "testX['cpilfesl'] = testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c893e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of input and output time steps\n",
    "n_steps_in = 12\n",
    "n_steps_out = 3\n",
    "\n",
    "# Split the data into input/output sequences\n",
    "x_train,y_train = split_sequences(trainX, n_steps_in, n_steps_out)\n",
    "\n",
    "# Split the data into input/output sequences\n",
    "x_test,y_test = split_sequences(testX, n_steps_in, n_steps_out)\n",
    "\n",
    "\n",
    "# Check the shape of the input/output sequences\n",
    "#print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0690e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 12, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b501b3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5073fd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 12, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a96e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "661db949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 17:43:20.529233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 9s 110ms/step - loss: 11.1716 - val_loss: 4.9647\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 6.6680 - val_loss: 2.1677\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 4.0035 - val_loss: 0.7911\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 1s 65ms/step - loss: 2.0108 - val_loss: 0.5179\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.1330 - val_loss: 0.6182\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.7475 - val_loss: 0.6930\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.6073 - val_loss: 0.9903\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.5001 - val_loss: 1.1497\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4069 - val_loss: 0.8431\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3478 - val_loss: 1.0586\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3450 - val_loss: 1.0426\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3146 - val_loss: 0.8804\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3511 - val_loss: 1.0177\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.2853 - val_loss: 1.3606\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2757 - val_loss: 0.9559\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2631 - val_loss: 0.9509\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.2327 - val_loss: 0.8340\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.2357 - val_loss: 0.8988\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.2303 - val_loss: 0.9346\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2205 - val_loss: 1.0555\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.2505 - val_loss: 0.9387\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 0.2350 - val_loss: 0.9538\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2212 - val_loss: 0.9853\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2355 - val_loss: 0.7080\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.2333 - val_loss: 0.7187\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2209 - val_loss: 0.7317\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2184 - val_loss: 0.5986\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2158 - val_loss: 0.6893\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.2365 - val_loss: 0.6970\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.2020 - val_loss: 0.7176\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.1747 - val_loss: 0.6975\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.1783 - val_loss: 0.7573\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.1953 - val_loss: 0.7911\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.2056 - val_loss: 0.6980\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.1973 - val_loss: 0.7330\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.7046\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2095 - val_loss: 0.6837\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2183 - val_loss: 0.7907\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1807 - val_loss: 0.8322\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1871 - val_loss: 0.7677\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2092 - val_loss: 0.5167\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1787 - val_loss: 0.5315\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1884 - val_loss: 0.5655\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1892 - val_loss: 0.5588\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1413 - val_loss: 0.5990\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1659 - val_loss: 0.5027\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1344 - val_loss: 0.6766\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1459 - val_loss: 0.6333\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1482 - val_loss: 0.6506\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.1714 - val_loss: 0.6697\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.1658 - val_loss: 0.6257\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.1375 - val_loss: 0.6992\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.1405 - val_loss: 0.6180\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.1426 - val_loss: 0.5400\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.1446 - val_loss: 0.4573\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.1460 - val_loss: 0.5888\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.1659 - val_loss: 0.7571\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.1262 - val_loss: 0.6018\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1573 - val_loss: 0.5925\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1295 - val_loss: 0.6700\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1575 - val_loss: 0.5917\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.1411 - val_loss: 0.7259\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1490 - val_loss: 0.6027\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.1205 - val_loss: 0.6538\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.1430 - val_loss: 0.7302\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1363 - val_loss: 0.7034\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1561 - val_loss: 0.8328\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 0.1536 - val_loss: 0.6593\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.1362 - val_loss: 0.5854\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 1s 25ms/step - loss: 0.1571 - val_loss: 0.5287\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1580 - val_loss: 0.5628\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.1480 - val_loss: 0.6696\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1580 - val_loss: 0.6181\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.1489 - val_loss: 0.6156\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.1527 - val_loss: 0.7162\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.1360 - val_loss: 0.6005\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 0.1411 - val_loss: 0.5970\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.1242 - val_loss: 0.6350\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.1304 - val_loss: 0.6578\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.1338 - val_loss: 0.5593\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 0.1430 - val_loss: 0.5901\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 26ms/step - loss: 0.1573 - val_loss: 0.6122\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1441 - val_loss: 0.6166\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.1338 - val_loss: 0.5979\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.1136 - val_loss: 0.6008\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.1456 - val_loss: 0.5169\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.1441 - val_loss: 0.5021\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.1233 - val_loss: 0.6408\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.1199 - val_loss: 0.6039\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.1346 - val_loss: 0.6130\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1381 - val_loss: 0.6679\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.1251 - val_loss: 0.5804\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.1260 - val_loss: 0.7367\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1390 - val_loss: 0.4936\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.1320 - val_loss: 0.5394\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.1271 - val_loss: 0.6042\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 0.1264 - val_loss: 0.6664\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 0.1400 - val_loss: 0.5685\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.1479 - val_loss: 0.4689\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1371 - val_loss: 0.5108\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1234 - val_loss: 0.5296\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.1230 - val_loss: 0.5644\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.1240 - val_loss: 0.5816\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.1222 - val_loss: 0.6208\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.1262 - val_loss: 0.6419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13901e080>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13901e410>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13901e290>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = x_train.shape[2]\n",
    "\n",
    "multi_model = Sequential()\n",
    "\n",
    "# Adding the LSTM layer and dropout regularizaiton\n",
    "multi_model.add(LSTM(100, return_sequences = True, input_shape=(n_steps_in, n_features)))\n",
    "multi_model.add(LSTM(100))\n",
    "multi_model.add(Dropout(0.2))\n",
    "\n",
    "# Adding output layer\n",
    "multi_model.add(Dense(n_steps_out))\n",
    "\n",
    "multi_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = 'mean_squared_error')\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', patience =50,\n",
    "                          mode = 'min',\n",
    "                          verbose = 0)\n",
    "\n",
    "fit = multi_model.fit(x_train, \n",
    "          y_train, validation_data = (x_test, y_test),   \n",
    "          epochs = 500, verbose=1, callbacks = [earlystop])\n",
    "\n",
    "\n",
    "# Check for overfitting\n",
    "plt.plot(fit.history['loss'], label = 'training', color = 'Blue')\n",
    "plt.plot(fit.history['val_loss'], label = 'validation', color = 'Red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afecb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 11ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "Variable 1, Perturbation Effect: 0.052\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "Variable 2, Perturbation Effect: 0.073\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "Variable 3, Perturbation Effect: 0.075\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "Variable 4, Perturbation Effect: 0.057\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "Variable 5, Perturbation Effect: 0.055\n"
     ]
    }
   ],
   "source": [
    "def feature_importance(model, g):\n",
    "    random_ind = np.random.choice(g.shape[0], 100, replace=False)\n",
    "    x = g[random_ind]\n",
    "    orig_out = model.predict(x)\n",
    "    for i in range(5):  # iterate over the 5 features\n",
    "        new_x = x.copy()\n",
    "        perturbation_in = np.random.normal(0.0, 0.7, size=new_x.shape[:2])\n",
    "        new_x[:, :, i] = new_x[:, :, i] + perturbation_in\n",
    "        perturbed_out = model.predict(new_x)\n",
    "        effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5\n",
    "        print(f'Variable {i+1}, Perturbation Effect: {effect:.3f}')\n",
    "\n",
    "feature_importance(multi_model, x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdb01bcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'expand_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testPredict \u001b[38;5;241m=\u001b[39m multi_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dim\u001b[49m(x_test[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inflation_forecasting/lib/python3.10/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'expand_dim'"
     ]
    }
   ],
   "source": [
    "testPredict = multi_model.predict(np.expand_dim(x_test[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c0aebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c0ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_min = scaler.data_min_  # get minimum values for features in x_train\n",
    "x_train_max = scaler.data_max_  # get maximum values for features in x_train\n",
    "y_train_min = scaler.data_min_  # get minimum value for target in y_train\n",
    "y_train_max = scaler.data_max_  # get maximum value for target in y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57a6c0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.11   ,  -1.95876,   3.4    , -15.19946,  -5.86048])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f693d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.1    , 14.59227, 10.8    , 13.382  , 13.78162])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be5994d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.11   ,  -1.95876,   3.4    , -15.19946,  -5.86048])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "887cb21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.1    , 14.59227, 10.8    , 13.382  , 13.78162])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73704373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max_scaler_x(x, x_min, x_max):\n",
    "    \"\"\"\n",
    "    A function that inverses MinMaxScaler on a given value.\n",
    "\n",
    "    Parameters:\n",
    "    x (float): The value to be inversed\n",
    "    x_min (float): The minimum value of the original feature\n",
    "    x_max (float): The maximum value of the original feature\n",
    "\n",
    "    Returns:\n",
    "    float: The inversed value\n",
    "    \"\"\"\n",
    "    return (x * (x_max - x_min)) + x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d67d8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_min_max_scaler_y(y, y_min, y_max):\n",
    "    \"\"\"\n",
    "    A function that inverses MinMaxScaler on a given value.\n",
    "\n",
    "    Parameters:\n",
    "    x (float): The value to be inversed\n",
    "    x_min (float): The minimum value of the original feature\n",
    "    x_max (float): The maximum value of the original feature\n",
    "\n",
    "    Returns:\n",
    "    float: The inversed value\n",
    "    \"\"\"\n",
    "    return (y * (y_max - y_min)) + y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fdbd553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33.567757 ,  31.148436 ,  28.378027 ],\n",
       "       [ 33.98645  ,  31.336405 ,  28.238085 ],\n",
       "       [ 34.011204 ,  31.265253 ,  27.937239 ],\n",
       "       [ 34.416195 ,  31.61122  ,  28.20101  ],\n",
       "       [ 34.73314  ,  31.951021 ,  28.548517 ],\n",
       "       [ 34.841946 ,  32.107075 ,  28.856886 ],\n",
       "       [ 34.849274 ,  32.207096 ,  29.114794 ],\n",
       "       [ 34.858673 ,  32.365948 ,  29.45865  ],\n",
       "       [ 35.32748  ,  32.92287  ,  30.214613 ],\n",
       "       [ 35.402733 ,  33.04337  ,  30.500349 ],\n",
       "       [ 34.19576  ,  31.96868  ,  29.61236  ],\n",
       "       [ 32.76089  ,  30.68881  ,  28.596357 ],\n",
       "       [ 30.655737 ,  28.649588 ,  26.8052   ],\n",
       "       [ 28.677515 ,  26.720015 ,  25.035301 ],\n",
       "       [ 26.724371 ,  24.764767 ,  23.157888 ],\n",
       "       [ 24.551542 ,  22.747698 ,  21.118698 ],\n",
       "       [ 22.633486 ,  21.070993 ,  19.449306 ],\n",
       "       [ 20.84157  ,  19.63676  ,  18.217806 ],\n",
       "       [ 19.491297 ,  18.687176 ,  17.608477 ],\n",
       "       [ 18.839489 ,  18.384117 ,  17.658165 ],\n",
       "       [ 18.257584 ,  18.071999 ,  17.634758 ],\n",
       "       [ 18.369326 ,  18.370077 ,  17.9596   ],\n",
       "       [ 17.648293 ,  17.703405 ,  17.217749 ],\n",
       "       [ 17.221264 ,  17.314905 ,  16.816631 ],\n",
       "       [ 17.935036 ,  18.0611   ,  17.547495 ],\n",
       "       [ 19.324856 ,  19.42194  ,  18.847471 ],\n",
       "       [ 20.46764  ,  20.54119  ,  19.92588  ],\n",
       "       [ 20.330067 ,  20.427586 ,  19.812101 ],\n",
       "       [ 19.177303 ,  19.243645 ,  18.62988  ],\n",
       "       [ 16.868187 ,  16.956068 ,  16.386911 ],\n",
       "       [ 15.169844 ,  15.214434 ,  14.628128 ],\n",
       "       [ 14.336231 ,  14.237526 ,  13.462183 ],\n",
       "       [ 13.127213 ,  13.109814 ,  12.287348 ],\n",
       "       [ 12.304155 ,  12.42725  ,  11.759394 ],\n",
       "       [ 12.68041  ,  12.92363  ,  12.400755 ],\n",
       "       [ 13.102022 ,  13.374929 ,  12.922182 ],\n",
       "       [ 13.343388 ,  13.576319 ,  13.12258  ],\n",
       "       [ 13.417656 ,  13.58334  ,  13.10771  ],\n",
       "       [ 13.376629 ,  13.514128 ,  13.010447 ],\n",
       "       [ 13.631168 ,  13.809328 ,  13.397163 ],\n",
       "       [ 14.787172 ,  15.038511 ,  14.76922  ],\n",
       "       [ 16.272213 ,  16.61106  ,  16.4468   ],\n",
       "       [ 17.58244  ,  18.07303  ,  18.020374 ],\n",
       "       [ 18.07101  ,  18.760109 ,  18.840963 ],\n",
       "       [ 16.381994 ,  17.176613 ,  17.42305  ],\n",
       "       [ 14.4891815,  15.453709 ,  15.886845 ],\n",
       "       [ 12.357151 ,  13.530209 ,  14.186781 ],\n",
       "       [ 10.743973 ,  12.140169 ,  12.9923115],\n",
       "       [  9.837526 ,  11.447084 ,  12.505409 ],\n",
       "       [  9.215216 ,  10.99465  ,  12.288265 ],\n",
       "       [  9.361734 ,  11.241663 ,  12.738827 ],\n",
       "       [  9.356861 ,  11.328102 ,  13.002222 ],\n",
       "       [  9.046795 ,  11.110472 ,  12.9843025],\n",
       "       [  8.992952 ,  11.189192 ,  13.2456875],\n",
       "       [  8.95826  ,  11.324038 ,  13.595671 ],\n",
       "       [  9.339661 ,  11.8848095,  14.370037 ],\n",
       "       [ 11.833622 ,  14.580811 ,  17.142145 ],\n",
       "       [ 13.768383 ,  16.64568  ,  19.180803 ],\n",
       "       [ 15.192141 ,  18.160334 ,  20.637615 ],\n",
       "       [ 17.164486 ,  20.217916 ,  22.552618 ],\n",
       "       [ 18.269777 ,  21.31518  ,  23.467123 ],\n",
       "       [ 19.335804 ,  22.311865 ,  24.259462 ],\n",
       "       [ 20.054567 ,  22.775692 ,  24.5519   ],\n",
       "       [ 21.1097   ,  23.580154 ,  25.181753 ],\n",
       "       [ 22.543734 ,  24.691008 ,  26.074434 ],\n",
       "       [ 23.738428 ,  25.566977 ,  26.728308 ],\n",
       "       [ 23.82582  ,  25.497671 ,  26.54207  ],\n",
       "       [ 24.016506 ,  25.592888 ,  26.53596  ],\n",
       "       [ 24.435656 ,  25.795248 ,  26.609453 ],\n",
       "       [ 25.735554 ,  26.951868 ,  27.729692 ],\n",
       "       [ 26.737593 ,  27.87226  ,  28.688025 ],\n",
       "       [ 27.568396 ,  28.57401  ,  29.411245 ],\n",
       "       [ 28.069063 ,  28.959913 ,  29.817266 ],\n",
       "       [ 28.42668  ,  29.199907 ,  30.067362 ],\n",
       "       [ 28.4852   ,  29.212412 ,  30.066214 ],\n",
       "       [ 29.074663 ,  29.787458 ,  30.632719 ],\n",
       "       [ 29.808146 ,  30.510466 ,  31.334402 ],\n",
       "       [ 30.440683 ,  31.05446  ,  31.847166 ],\n",
       "       [ 31.08977  ,  31.637205 ,  32.338253 ],\n",
       "       [ 32.10114  ,  32.70398  ,  33.42514  ],\n",
       "       [ 32.024536 ,  32.97767  ,  33.783955 ],\n",
       "       [ 30.750883 ,  31.923616 ,  32.708984 ],\n",
       "       [ 31.081263 ,  32.26189  ,  33.032444 ],\n",
       "       [ 32.400375 ,  33.50403  ,  34.288486 ],\n",
       "       [ 34.375546 ,  35.401913 ,  36.216846 ],\n",
       "       [ 35.88894  ,  36.847492 ,  37.703606 ],\n",
       "       [ 36.866554 ,  37.775234 ,  38.65697  ],\n",
       "       [ 36.074566 ,  36.948025 ,  37.816017 ],\n",
       "       [ 33.661896 ,  34.480362 ,  35.354706 ],\n",
       "       [ 32.669056 ,  33.458576 ,  34.399635 ],\n",
       "       [ 30.44549  ,  31.161959 ,  32.16399  ],\n",
       "       [ 27.513182 ,  28.281187 ,  29.291563 ],\n",
       "       [ 24.971703 ,  25.803864 ,  26.804628 ],\n",
       "       [ 24.458702 ,  25.333715 ,  26.319471 ],\n",
       "       [ 24.153578 ,  25.199354 ,  26.196775 ],\n",
       "       [ 23.506681 ,  24.73109  ,  25.789091 ],\n",
       "       [ 21.173473 ,  22.708237 ,  23.908432 ],\n",
       "       [ 19.330086 ,  21.059263 ,  22.369026 ],\n",
       "       [ 17.134453 ,  19.07946  ,  20.570011 ],\n",
       "       [ 17.142374 ,  19.123964 ,  20.77823  ],\n",
       "       [ 19.332987 ,  21.242683 ,  23.033922 ],\n",
       "       [ 23.323736 ,  25.255573 ,  27.178541 ],\n",
       "       [ 32.495914 ,  34.26143  ,  36.203346 ],\n",
       "       [ 41.032356 ,  42.328568 ,  43.98569  ],\n",
       "       [ 47.62004  ,  48.45747  ,  49.65277  ],\n",
       "       [ 50.794    ,  51.491653 ,  52.566734 ],\n",
       "       [ 43.078    ,  43.30917  ,  44.39571  ],\n",
       "       [ 28.80977  ,  28.972906 ,  30.450846 ],\n",
       "       [ 20.847683 ,  21.601252 ,  23.585531 ],\n",
       "       [ 16.824512 ,  18.123095 ,  20.108322 ],\n",
       "       [ 16.394897 ,  17.867495 ,  19.200533 ],\n",
       "       [ 17.49242  ,  18.806559 ,  19.25429  ],\n",
       "       [ 18.81846  ,  19.889006 ,  19.54493  ],\n",
       "       [ 19.588118 ,  20.398876 ,  19.464722 ],\n",
       "       [ 19.79555  ,  20.383621 ,  19.096996 ],\n",
       "       [ 18.795279 ,  19.368067 ,  18.148352 ],\n",
       "       [ 18.652512 ,  19.164879 ,  17.963966 ],\n",
       "       [ 19.114378 ,  19.531412 ,  18.208918 ],\n",
       "       [ 18.893946 ,  19.155684 ,  18.07722  ],\n",
       "       [ 20.024925 ,  20.530252 ,  20.285555 ],\n",
       "       [ 23.101885 ,  23.719872 ,  23.79824  ],\n",
       "       [ 30.124132 ,  31.059618 ,  31.522871 ],\n",
       "       [ 39.31476  ,  40.63105  ,  41.626076 ],\n",
       "       [ 46.5633   ,  47.5856   ,  48.62958  ],\n",
       "       [ 52.381054 ,  52.727676 ,  53.70565  ],\n",
       "       [ 59.70662  ,  59.41606  ,  60.503098 ],\n",
       "       [ 70.87838  ,  70.030426 ,  71.31474  ],\n",
       "       [ 88.57871  ,  87.23369  ,  88.45256  ],\n",
       "       [101.534134 ,  99.367424 ,  99.708496 ],\n",
       "       [105.491425 , 103.59493  , 104.32193  ],\n",
       "       [110.76269  , 109.42113  , 110.99637  ],\n",
       "       [112.810394 , 110.75339  , 111.22445  ],\n",
       "       [113.40714  , 110.92477  , 110.182625 ],\n",
       "       [117.48421  , 115.04038  , 114.12509  ],\n",
       "       [121.37725  , 118.8834   , 117.850266 ],\n",
       "       [127.76809  , 125.25272  , 124.138954 ],\n",
       "       [135.96281  , 133.95973  , 133.34517  ],\n",
       "       [138.94923  , 137.18007  , 136.5906   ],\n",
       "       [139.14543  , 137.30428  , 136.51851  ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_min_max_scaler_y(testPredict,y_train_min[-1], y_train_max[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine y_test_hat for Prediction\n",
    "y_test_hat = np.concatenate((x_test[:, 2, 1:5], testPredict), axis=1)\n",
    "y_test_hat = y_test_hat[:, 3]\n",
    "\n",
    "# Determine Actual\n",
    "testY_actual = np.concatenate((x_test[:, 2, 1:5], y_test), axis=1)\n",
    "y_test_actual = testY_actual[:, 3]\n",
    "\n",
    "# Check shapes of both arrays\n",
    "print(\"Shape of y_test_hat:\", y_test_hat.shape)\n",
    "print(\"Shape of y_test_actual:\", y_test_actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine y_test_hat for Prediction\n",
    "y_test_hat = multi_model.predict(testX)\n",
    "\n",
    "# Determine Actual\n",
    "testY_actual = testY.reshape((len(testY), n_future))\n",
    "\n",
    "# Check shapes of both arrays\n",
    "print('Shape of y_test_hat:', y_test_hat.shape)\n",
    "print('Shape of testY_actual:', testY_actual.shape)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(testY_actual, y_test_hat, squared=False)\n",
    "print('Test RMSE: %.3f' % mse)\n",
    "\n",
    "# Calculate mean model error\n",
    "model_error = testY_actual - y_test_hat\n",
    "print('Mean Model Error: %.3f' % model_error.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mse = mean_squared_error(testY_actual, y_test_hat)\n",
    "print(f'Test MSE: {mse:.3f}')\n",
    "\n",
    "# Calculate mean model error\n",
    "model_error = testY_actual - y_test_hat\n",
    "print(f'Mean Model Error: {model_error.mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd20ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
