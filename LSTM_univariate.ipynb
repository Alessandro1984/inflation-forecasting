{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faf93cc",
   "metadata": {},
   "source": [
    "# !!!NOTE!!! Every time the model is trained it will produced a difference forecast. So no need to save the model again :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa0d328",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Deep Learning\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Dealing with temporal data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Sequence\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dealing with temporal data\n",
    "from typing import Dict, List, Tuple, Sequence\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20967ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "csv_path = os.path.join('..', 'inflation-forecasting', 'raw_data')\n",
    "\n",
    "df = pd.read_csv(os.path.join(csv_path,'data_final.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd936f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe94c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = df[df['country_id'] == \"USA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac04284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccpi = pd.DataFrame(df_it['ccpi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_errorccpi = ccpi.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(ccpi.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ebf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "\n",
    "data = dataset[0:]\n",
    "\n",
    "X, Y = split_sequence(data, n_steps_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "\n",
    "uni_model = models.Sequential()\n",
    "uni_model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   input_shape = (X.shape[1], n_features)))\n",
    "uni_model.add(Dense(1, \n",
    "                    activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe739f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "\n",
    "uni_model = models.Sequential()\n",
    "uni_model.add(LSTM(64, input_shape=(X.shape[1], n_features))) # Adding the LSTM layer\n",
    "uni_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2664b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.02) \n",
    "\n",
    "uni_model.compile(loss='mse', \n",
    "                  optimizer=adam, \n",
    "                  metrics=[\"mse\"])\n",
    "\n",
    "fit = uni_model.fit(X, \n",
    "                    Y,   \n",
    "                    epochs = 25, \n",
    "                    batch_size=1,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting\n",
    "plt.plot(fit.history['loss'], label = 'training', color = 'Blue')\n",
    "#plt.plot(fit.history['val_loss'], label = 'validation', color = 'Red')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac952659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = uni_model.predict(X)\n",
    "\n",
    "Y_hat = scaler.inverse_transform(Predict)\n",
    "\n",
    "Y_actual = scaler.inverse_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(Y_actual)\n",
    "data2 = pd.DataFrame(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data1)\n",
    "plt.plot(data2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eadc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 12\n",
    "x_input = np.array(dataset[-12:])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "forecast_normalized = uni_model.predict(x_input)\n",
    "forecast = scaler.inverse_transform(forecast_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# Append the predition\n",
    "# Shift the data\n",
    "# Fit the model again\n",
    "# Repeat ...\n",
    "# Normalize invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_forecasting(dataset, model, mb=12, mf=12):\n",
    "    '''\n",
    "    Returns the future forecasting of the model. Please select the dataset and model you want to use.\n",
    "    for mb, select the number of months you want to look back to make a prediction. \n",
    "    for mf, select the number of months you want the prediction to look forward.\n",
    "    '''\n",
    "    results = []\n",
    "    x_input = dataset[-mb:].reshape(1, mb, 1)\n",
    "    for num in range(mf):\n",
    "        forecast = model.predict(x_input)\n",
    "        results.append(forecast[0][0])\n",
    "        x_input = np.roll(x_input, -1, axis=1)\n",
    "        x_input[0][-1] = forecast\n",
    "    results = scaler.inverse_transform(np.array(results).reshape(-1, 1)) # reshape dataset to 2D array\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8252e71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = future_forecasting(dataset,uni_model,mb=12,mf=24)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffe3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb736c",
   "metadata": {},
   "source": [
    "# Save the model for the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uni_model.save(\"model_usa.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
